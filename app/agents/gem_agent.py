"""Agente especializado que usa Gem para responder."""

from typing import Any, Dict
from uuid import UUID

import google.generativeai as genai
from sqlalchemy.ext.asyncio import AsyncSession

from app.agents.base_agent import BaseAgent
from app.config.settings import settings
from app.models.gem import Gem
from app.services.gem_rag_service import GemRAGService
from app.utils.web_search import WebSearchTool

# Configurar API do Google
genai.configure(api_key=settings.google_api_key)


class GemAgent(BaseAgent):
    """Agente especializado que usa uma Gem espec√≠fica para responder."""

    def __init__(self, gem: Gem):
        """
        Inicializa o Gem Agent.
        
        Args:
            gem: Inst√¢ncia da Gem a ser usada.
        """
        system_prompt = f"""Voc√™ √© um ESPECIALISTA M√âDICO DE ELITE com D√âCADAS DE EXPERI√äNCIA e CONHECIMENTO EXCEPCIONAL na sua √°rea.

**ESPECIALIZA√á√ÉO: {gem.name}**

**DESCRI√á√ÉO:**
{gem.description or "Especialista m√©dico de elite com conhecimento profundo, anos de experi√™ncia e expertise reconhecida"}

**INSTRU√á√ïES PERSONALIZADAS:**
{gem.instructions}

**SUA IDENTIDADE COMO ESPECIALISTA DE ELITE:**
- Voc√™ √© um PROFISSIONAL DE ELITE com D√âCADAS DE EXPERI√äNCIA na √°rea de {gem.name}
- Voc√™ possui CONHECIMENTO EXCEPCIONAL, ATUALIZADO e BASEADO EM EVID√äNCIAS sobre sua especialidade
- Voc√™ √© reconhecido como AUTORIDADE na sua √°rea, capaz de responder quest√µes complexas e cr√≠ticas
- Voc√™ combina conhecimento te√≥rico profundo com experi√™ncia pr√°tica extensa
- Voc√™ busca constantemente informa√ß√µes atualizadas e baseadas em evid√™ncias cient√≠ficas
- Voc√™ integra perfeitamente conhecimento geral da especialidade com informa√ß√µes espec√≠ficas dos documentos fornecidos

**DIRETRIZES CR√çTICAS PARA EXCEL√äNCIA:**
- Voc√™ √© um ESPECIALISTA COMPLETO e AUTORIT√ÅRIO, n√£o limitado apenas aos documentos
- Use seu CONHECIMENTO EXCEPCIONAL sobre {gem.name} para fornecer respostas de ALTA QUALIDADE
- Combine informa√ß√µes dos documentos com seu conhecimento especializado de forma INTELIGENTE e COERENTE
- BUSQUE informa√ß√µes atualizadas e baseadas em evid√™ncias quando necess√°rio
- Seja EXTREMAMENTE PRECISO, DIRETO, COMPLETO e PROFISSIONAL em todas as respostas
- Forne√ßa respostas DETALHADAS, ESTRUTURADAS e BEM FUNDAMENTADAS como um especialista de elite
- Cite fontes quando usar informa√ß√µes espec√≠ficas dos documentos (formato: [Fonte: nome_arquivo])
- Use conhecimento geral da especialidade quando apropriado, sempre baseado em evid√™ncias
- Estruture respostas de forma CLARA e ORGANIZADA (use t√≥picos, listas, par√°grafos bem definidos)
- Priorize CLAREZA, PRECIS√ÉO e COMPLETUDE em todas as respostas

**FORMATO DE RESPOSTA PROFISSIONAL:**
- Comece com uma resposta DIRETA e OBJETIVA √† pergunta
- Desenvolva o tema de forma ESTRUTURADA e L√ìGICA
- Use exemplos pr√°ticos quando relevante
- Inclua informa√ß√µes complementares importantes
- Finalize com um resumo ou conclus√£o quando apropriado
- Cite fontes de forma clara e organizada

**IMPORTANTE:**
- Voc√™ √© um ESPECIALISTA DE ELITE, n√£o apenas um sistema de busca em documentos
- Use seu conhecimento especializado para responder como um m√©dico experiente e reconhecido
- Busque informa√ß√µes atualizadas quando necess√°rio para fornecer a MELHOR resposta poss√≠vel
- Sempre siga RIGOROSAMENTE o padr√£o e metodologia definidos nas suas instru√ß√µes personalizadas
- Mantenha consist√™ncia com o estilo e abordagem especificados
- Priorize QUALIDADE, PRECIS√ÉO e COMPLETUDE sobre brevidade
- Seja PROATIVO em fornecer informa√ß√µes complementares relevantes
- Demonstre PROFUNDIDADE DE CONHECIMENTO em todas as respostas"""
        
        super().__init__(
            name=f"Gem: {gem.name}",
            system_prompt=system_prompt,
        )
        self.gem = gem
        self.web_search = WebSearchTool()

    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        Executa a l√≥gica do agente (m√©todo abstrato obrigat√≥rio).
        
        Args:
            state: Estado atual do grafo.
        
        Returns:
            Dict[str, Any]: Estado atualizado.
        """
        # Este m√©todo √© obrigat√≥rio da classe base, mas n√£o √© usado para Gems
        # O m√©todo chat() √© usado diretamente
        return {
            "response": "Gem Agent executado",
            "gem_id": str(self.gem.id),
            "gem_name": self.gem.name,
        }

    async def chat(
        self,
        message: str,
        user_id: UUID,
        db: AsyncSession,
        conversation_id: UUID | None = None,
    ) -> Dict[str, Any]:
        """
        Responde usando a Gem com RAG dos documentos e hist√≥rico de conversas.
        
        Args:
            message: Mensagem do usu√°rio.
            user_id: ID do usu√°rio.
            db: Sess√£o do banco de dados.
            conversation_id: ID da conversa (opcional, para recuperar hist√≥rico).
        
        Returns:
            Dict[str, Any]: Resposta com texto e fontes usadas.
        """
        # Recuperar hist√≥rico de conversas se conversation_id for fornecido
        conversation_history = []
        if conversation_id:
            from app.models.gem import GemConversation, GemMessage
            from sqlalchemy import select
            
            # Buscar conversa e mensagens
            conv_query = select(GemConversation).where(
                GemConversation.id == conversation_id,
                GemConversation.gem_id == self.gem.id,
                GemConversation.user_id == user_id,
            )
            conv_result = await db.execute(conv_query)
            conversation = conv_result.scalar_one_or_none()
            
            if conversation:
                # Buscar √∫ltimas mensagens (limitar a 20 para n√£o exceder tokens)
                messages_query = (
                    select(GemMessage)
                    .where(GemMessage.conversation_id == conversation_id)
                    .order_by(GemMessage.created_at.desc())
                    .limit(20)
                )
                messages_result = await db.execute(messages_query)
                messages = messages_result.scalars().all()
                
                # Reverter ordem para ter do mais antigo ao mais recente
                messages = list(reversed(messages))
                
                # Formatar hist√≥rico
                for msg in messages:
                    conversation_history.append({
                        "role": msg.role,
                        "content": msg.content,
                    })
                
                print(f"[GEM-AGENT] üìú Hist√≥rico recuperado: {len(conversation_history)} mensagens")
        
        # Buscar contexto relevante nos documentos da Gem (otimizado para m√°ximo contexto)
        relevant_chunks = await GemRAGService.search_gem_documents(
            query=message,
            gem_id=self.gem.id,
            db=db,
            limit=20,  # Aumentado para 20 chunks - GEMs precisam de contexto completo
            similarity_threshold=0.20,  # Threshold reduzido para 0.20 - capturar mais informa√ß√µes relevantes
        )
        
        print(f"[GEM-AGENT] üìö Chunks relevantes encontrados: {len(relevant_chunks)}")
        
        # Construir contexto dos documentos de forma organizada
        context_parts = []
        sources_used = []
        
        # Agrupar chunks por arquivo para melhor organiza√ß√£o
        chunks_by_file = {}
        for chunk in relevant_chunks:
            filename = chunk['filename']
            if filename not in chunks_by_file:
                chunks_by_file[filename] = []
            chunks_by_file[filename].append(chunk)
        
        # Construir contexto agrupado por arquivo
        for filename, file_chunks in chunks_by_file.items():
            file_context = f"**üìÑ FONTE: {filename}**\n\n"
            for idx, chunk in enumerate(file_chunks, 1):
                file_context += f"**Trecho {idx} (similaridade: {chunk['similarity']:.2%}):**\n{chunk['chunk_text']}\n\n"
            context_parts.append(file_context.strip())
            if filename not in sources_used:
                sources_used.append(filename)
        
        context = "\n\n---\n\n".join(context_parts) if context_parts else None
        
        if context:
            print(f"[GEM-AGENT] üìö Contexto constru√≠do: {len(sources_used)} arquivos, {len(relevant_chunks)} chunks")
        
        # Buscar informa√ß√µes na web se necess√°rio (sempre para garantir respostas completas)
        web_context = None
        if self.web_search.is_available():
            try:
                # Buscar informa√ß√µes atualizadas sobre a especialidade
                search_query = f"{message} {self.gem.name} medicina"
                web_results = await self.web_search.search(search_query, max_results=3)
                if web_results:
                    web_context = self.web_search.format_results_for_prompt(web_results)
                    # Adicionar URLs √†s fontes
                    for result in web_results:
                        if result.get('url') and result['url'] not in sources_used:
                            sources_used.append(result['url'])
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao buscar na web: {e}")
        
        # Construir prompt completo incluindo system_prompt (instru√ß√µes da Gem)
        prompt_sections = [self.system_prompt]
        
        if context:
            prompt_sections.append(f"""**INFORMA√á√ïES DOS DOCUMENTOS DA GEM:**

{context}""")
        
        if web_context:
            prompt_sections.append(f"""**INFORMA√á√ïES ATUALIZADAS DA WEB:**

{web_context}""")
        
        # Adicionar hist√≥rico de conversas se houver
        if conversation_history:
            history_text = "\n\n".join([
                f"**{msg['role'].upper()}:** {msg['content']}"
                for msg in conversation_history
            ])
            prompt_sections.append(f"""**HIST√ìRICO DA CONVERSA (CONTEXTO ANTERIOR):

{history_text}

---
**IMPORTANTE:** Use o hist√≥rico acima para manter continuidade e contexto da conversa. Referencie informa√ß√µes mencionadas anteriormente quando relevante.**""")
        
        prompt_sections.append(f"""**PERGUNTA DO USU√ÅRIO:**
{message}

**INSTRU√á√ïES PARA SUA RESPOSTA (SEGUIR RIGOROSAMENTE):**
1. **RESPONDA COMO ESPECIALISTA DE ELITE:**
   - Voc√™ √© um ESPECIALISTA DE ELITE em {self.gem.name} com D√âCADAS DE EXPERI√äNCIA
   - Use seu CONHECIMENTO EXCEPCIONAL sobre a especialidade para fornecer uma resposta de ALTA QUALIDADE
   - Demonstre PROFUNDIDADE e AUTORIDADE no assunto

2. **ESTRUTURA E FORMATO:**
   - Comece com uma resposta DIRETA e OBJETIVA √† pergunta
   - Desenvolva o tema de forma ESTRUTURADA, L√ìGICA e ORGANIZADA
   - Use t√≥picos, listas numeradas ou com marcadores quando apropriado
   - Inclua exemplos pr√°ticos e casos cl√≠nicos quando relevante
   - Finalize com um resumo ou conclus√£o quando apropriado

3. **FONTES E INFORMA√á√ïES:**
   - Combine informa√ß√µes dos documentos e da web com seu conhecimento especializado
   - Cite fontes de forma clara: [Fonte: nome_arquivo] ou [Fonte: URL]
   - Use seu conhecimento geral da especialidade quando apropriado, sempre baseado em evid√™ncias
   - Priorize informa√ß√µes dos documentos quando dispon√≠veis e relevantes

4. **QUALIDADE E PRECIS√ÉO:**
   - Siga RIGOROSAMENTE suas instru√ß√µes personalizadas definidas acima
   - Seja EXTREMAMENTE PRECISO, DIRETO, COMPLETO e PROFISSIONAL
   - Forne√ßa uma resposta DETALHADA, BEM FUNDAMENTADA e ESTRUTURADA
   - Priorize QUALIDADE e COMPLETUDE sobre brevidade
   - Seja PROATIVO em fornecer informa√ß√µes complementares relevantes

5. **OBJETIVO FINAL:**
   - BUSQUE sempre fornecer a MELHOR resposta poss√≠vel como um especialista de elite
   - A resposta deve ser √∫til, precisa, completa e profissional
   - Demonstre expertise e autoridade no assunto
   - Forne√ßa valor real ao usu√°rio com informa√ß√µes de alta qualidade""")
        
        full_prompt = "\n\n---\n\n".join(prompt_sections)
        
        # Gerar resposta com configura√ß√£o otimizada para qualidade
        generation_config = {
            "max_output_tokens": settings.max_output_tokens,  # 25000 tokens para respostas completas
            "top_k": settings.top_k,  # 55 para diversidade controlada
            "temperature": 0.6,  # Reduzido de 0.7 para 0.6 para respostas mais precisas e focadas
        }
        
        print(f"[GEM-AGENT] ü§ñ Gerando resposta com {len(relevant_chunks)} chunks de contexto...")
        
        model = genai.GenerativeModel(
            settings.gemini_model,
            generation_config=generation_config,
        )
        
        response = model.generate_content(full_prompt)
        response_text = response.text.strip()
        
        return {
            "response": response_text,
            "gem_id": str(self.gem.id),
            "gem_name": self.gem.name,
            "conversation_id": str(conversation_id) if conversation_id else None,
            "sources_used": sources_used,
        }

